# Awesome-XAI-Evaluation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

An awesome and organized reference list of evaluation measures and methods for explainable machine learning (XAI) algorithms and systems. If you need more details and descriptions, you can read the [*full paper*](https://arxiv.org/pdf/1811.11839.pdf) or visit [my page](http://people.tamu.edu/~sina.mohseni/webpage/research.html)for new resources!


## How to Evaluate XAI?

We reviewed XAI-related research to organize different XAI design goals and evaluation measures. This awesome-list presents our categorization of selected existing design and evaluation methods that organizes literature along three perspectives: **design goals**, **evaluation methods**, and **targeted users** of the XAI system. We provide summarized ready-to-use tables of evaluation methods and recommendations for different goals in XAI research. 
<!-- ## What is this awesome list about? -->


## Evaluation Methods

* **Computational Measures**
   * [Fidelity of Interpretability Method](#fidelity-of-interpretability-method)
   * [Model Trustworthiness](#model-trustworthiness)
* **Human-grounded Measures**
   * [Human-machine Task Performance](#human-machine-task-performance)
   * [User Mental Model](#user-mental-model)
   * [User Trust and Reliance](#conferences)
   * [Explanation Usefulness and Satisfaction](#explanation-usefulness-and-satisfaction)
  

## Fidelity of Interpretability Method


## Model Trustworthiness


## Human-machine Task Performance


## User Mental Model


## User Trust and Reliance


## Explanation Usefulness and Satisfaction
  
